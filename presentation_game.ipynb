{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddfbab22",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# AI Agent - Castle Isolation\n",
    "\n",
    "In this project, I engineered a series of sophisticated AI agents designed to compete in the game of Castle Isolation, demonstrating varying levels of strategic depth and computational efficiency. The core of these agents' capabilities was underpinned by a robust implementation of several well-established algorithms in game theory and artificial intelligence, including:\n",
    "\n",
    "#### Minimax Algorithm \n",
    "This fundamental game-playing algorithm was employed to exhaustively explore possible moves and their implications, aiming to minimize the possible loss for a worst-case scenario.\n",
    "#### Alpha-Beta Pruning\n",
    "I enhanced the Minimax search efficiency by integrating Alpha-Beta pruning, which significantly reduces the number of nodes evaluated in the search tree, thereby optimizing performance without sacrificing decision quality.\n",
    "#### Iterative Deepening\n",
    "I applied this technique to combine the advantages of depth-first and breadth-first search strategies. It incrementally deepens the search allowing the algorithm to use more manageable iterations and improve time management by using results from previous iterations.\n",
    "#### Evaluation Functions\n",
    "I developed sophisticated evaluation functions that provide a heuristic assessment of game\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e82627",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Disclaimer and Copyright Notice\n",
    "\n",
    "1. The algorithms and techniques shown in this report were developed by me, Franz Adam. If code is used, please give credit accordingly. \n",
    "2. Since the implementation of algorithms overlaps with material in CS university courses, I advise current students to adhere to their academic institution's policies regarding integrity and plagiarism before continuing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547de584",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## About the Game\n",
    "The rules of Castle Isolation are a variation of the original Isolation game. In the original form of the game there are two players, each with their own game piece, and a 7-by-7 grid of squares. At the beginning of the game, the first player places their piece on any square. The second player follows suit, and places their piece on any one of the available squares. From that point on, the players alternate turns moving their piece like a queen in chess (any number of open squares vertically, horizontally, or diagonally). When the piece is moved, the square that was previously occupied is blocked, and cannot be used for the remainder of the game. The first player who is unable to move their queen loses.\n",
    "\n",
    "In this variant called Castle Isolation, We have a 9-by-9 grid in this variation. There are 12 pre-defined squares which are blocked so as to create a castle-like structure. Neither players can move on or through squares that are blocked. The game ends when one of the players is not able to make a move and is trapped. For clarity, examine the scenario below:\n",
    "\n",
    "### Rules visualized\n",
    "Below is a depiction of the empty starting board position.\n",
    "\n",
    "<div>\n",
    "<img src=\"./img/starting_board.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "Q1 places their queen on the board, and Q2 follows suit.\n",
    "\n",
    "<div>\n",
    "<img src=\"./img/castle_isolation_1.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "Q1 moves vertically down for 3 blocks, consequently blocking some of Q2's potential future moves. The previous location of Q1 is also blocked as shown below.\n",
    "\n",
    "<div>\n",
    "<img src=\"./img/castle_isolation_2.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "Q2 makes a one block move diagonally downward to the left simply blocking the previously held location.\n",
    "\n",
    "<div>\n",
    "<img src=\"./img/castle_isolation_3.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "Both the players play a number of moves and the following is an example of when the game ends and Q2 wins. Q2 wins as there are no more possible moves for Q1!\n",
    "\n",
    "<div>\n",
    "<img src=\"./img/castle_isolation_4.png\" width=\"500\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dce2b22",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### For more clarity, You can try playing the game against the Random Player or yourself using the interactive tool below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ba2af1",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Following two lines make sure anything imported from .py scripts͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁 \n",
    "# is automatically reloaded if edited & saved (e.g. local unit tests or players)͏󠄂͏️͏󠄌͏󠄎͏󠄎͏󠄊͏󠄁\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from board_viz import ReplayGame, InteractiveGame\n",
    "from isolation import Board\n",
    "from test_players import RandomPlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eb70bbe",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from isolation import Board"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb5ee49",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluation Functions\n",
    "\n",
    "The design of evaluation functions is pivotal in the development of game-playing AI agents. An effective evaluation function provides a heuristic estimate of the state's value, enabling the AI to make informed decisions by approximating the game's outcome from any given position.\n",
    "\n",
    "For the game of Castle Isolation the evaluation function is crucial for assessing board configurations. Advanced functions often incorporate multiple heuristic indicators, such as the mobility of a piece (the number of available moves), control of the center, and potential pathways for trapping the opponent. These metrics reflect strategic nuances and foresight, allowing the AI to plan moves that maximize its positional advantage while minimizing future options for the opponent. \n",
    "\n",
    "One of the most intuitive and basic evaluation functions is the number of available legal moves for a given board configuration. This is what levels 1 and 2 use for my AI agent and what is depicted below. My level 3 agetn uses a specialized evaluation function which I will share with the reader when they successfully defeat my level 3 AI agent. \n",
    "\n",
    "The evaluation function is not just a tool for decision making in non-terminal states; it encapsulates the strategic essence of the game, translating abstract concepts like control, threat, and potential into actionable metrics that drive the AI’s performance towards victory.\n",
    "\n",
    "```python \n",
    "class OpenMoveEvalFn:\n",
    "    def score(self, game, my_player=None):\n",
    "        \"\"\"Score the current game state\n",
    "        Basic Evaluation function that outputs a score equal to how many\n",
    "        moves are open for AI player on the board minus how many moves\n",
    "        are open for Opponent's player on the board.\n",
    "\n",
    "            Args\n",
    "                game (Board): The board and game state.\n",
    "                my_player (Player object): This specifies which player you are.\n",
    "\n",
    "            Returns:\n",
    "                float: The current state's score. MyMoves-OppMoves.\n",
    "\n",
    "            \"\"\"\n",
    "        player_moves = len(game.get_player_moves(my_player))\n",
    "        opponent_moves = len(game.get_opponent_moves(my_player))\n",
    "\n",
    "        ... # Here lies the hidden evaluation function. Defeat my level 3 AI agent and I will share it with you!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c35946d",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "class CustomPlayer:\n",
    "    \"\"\"Player class that chooses a move using the evaluation function\n",
    "    and applied algorithm.\"\"\"\n",
    "\n",
    "    def __init__(self, search_depth=4, eval_fn=OpenMoveEvalFn()):\n",
    "        \n",
    "        self.eval_fn = eval_fn\n",
    "        self.search_depth = search_depth\n",
    "    \n",
    "    def move(self, game, time_left):\n",
    "        \"\"\"Called to determine one move by your agent\n",
    "        Args:\n",
    "            game (Board): The board and game state.\n",
    "            time_left (function): Used to determine time left before timeout\n",
    "\n",
    "        Returns:\n",
    "            tuple: (int,int): Your best move\n",
    "        \"\"\"\n",
    "        \n",
    "        # Iterative deepening\n",
    "        max_depth = 24\n",
    "        best_moves = []\n",
    "        \n",
    "        for depth in range(1, max_depth + 1):     \n",
    "            best_move, utility = alphabeta(self, game, time_left, depth = self.search_depth - self.search_depth + depth)\n",
    "            best_moves.append(best_move)\n",
    "    \n",
    "            if best_moves[-1] == (-1,-1):\n",
    "                return best_moves[-2]\n",
    "                \n",
    "        return best_move\n",
    "\n",
    "    def utility(self, game, my_turn):\n",
    "        \"\"\"I handle special cases here (e.g. endgame)\"\"\"\n",
    "        \n",
    "        return self.eval_fn.score(game, self)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78195aa9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Minimax\n",
    "My implementation of the minimax algorithm.\n",
    "\n",
    "```python\n",
    "def minimax(player, game, time_left, depth, my_turn=True):\n",
    "    \"\"\"Implementation of the minimax algorithm.\n",
    "    Args:\n",
    "        player (CustomPlayer): This is the instantiation of CustomPlayer()\n",
    "            that represents your agent. It is used to call anything you\n",
    "            need from the CustomPlayer class (the utility() method, for example,\n",
    "            or any class variables that belong to CustomPlayer()).\n",
    "        game (Board): A board and game state.\n",
    "        time_left (function): Used to determine time left before timeout\n",
    "        depth: Used to track how deep you are in the search tree\n",
    "        my_turn (bool): True if you are computing scores during your turn.\n",
    "\n",
    "    Returns:\n",
    "        (tuple, int): best_move, val\n",
    "    \"\"\"\n",
    "    \n",
    "    #Base Case:\n",
    "    #if depth is reached or game is over (e.g., no more active moves for one player)\n",
    "    if depth == 0:\n",
    "        return (None, player.utility(game, my_turn))\n",
    "    #return score of current position\n",
    "\n",
    "    #Recursive Call\n",
    "    if my_turn:\n",
    "        best_cost = float(\"-inf\")\n",
    "        best_move = None\n",
    "        \n",
    "        for move in game.get_active_moves():\n",
    "            _, eval = minimax(player, game.forecast_move(move)[0], time_left, depth - 1, my_turn = False)\n",
    "            if eval > best_cost:\n",
    "                best_cost = eval\n",
    "                best_move = move\n",
    "        return (best_move, best_cost)\n",
    "        \n",
    "    else: \n",
    "        best_cost = float(\"inf\")\n",
    "        best_move = None\n",
    "        \n",
    "        for move in game.get_active_moves():\n",
    "            _, eval = minimax(player, game.forecast_move(move)[0], time_left, depth - 1, my_turn = True)\n",
    "            if eval < best_cost:\n",
    "                best_cost = eval\n",
    "                best_move = move\n",
    "        return (best_move, best_cost)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dae12c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Alphabeta Pruning\n",
    "This is my implementation of the alphabeta pruning optimization technique for the Minimax algorithm.\n",
    "\n",
    "``` python\n",
    "def alphabeta(player, game, time_left, depth, alpha=float(\"-inf\"), beta=float(\"inf\"), my_turn=True):\n",
    "    \"\"\"Implementation of the alphabeta algorithm.\n",
    "    \n",
    "    Args:\n",
    "        player (CustomPlayer): This is the instantiation of CustomPlayer() \n",
    "            that represents your agent. It is used to call anything you need \n",
    "            from the CustomPlayer class (the utility() method, for example, \n",
    "            or any class variables that belong to CustomPlayer())\n",
    "        game (Board): A board and game state.\n",
    "        time_left (function): Used to determine time left before timeout\n",
    "        depth: Used to track how deep you are in the search tree\n",
    "        alpha (float): Alpha value for pruning\n",
    "        beta (float): Beta value for pruning\n",
    "        my_turn (bool): True if you are computing scores during your turn.\n",
    "        \n",
    "    Returns:\n",
    "        (tuple, int): best_move, val\n",
    "    \"\"\"\n",
    "    \n",
    "    if depth == 0 or len(game.get_active_moves()) == 0:\n",
    "        return (None, player.utility(game, my_turn))\n",
    "\n",
    "    if time_left() < 30: #Was 60 at 95pt submission \n",
    "        print(time_left())\n",
    "        return (-1,-1), -100\n",
    "    \n",
    "    if my_turn:\n",
    "        best_score, best_move = float(\"-inf\"), None\n",
    "        for move in game.get_active_moves():\n",
    "            _, eval = alphabeta(player, game.forecast_move(move)[0], time_left, depth - 1, alpha, beta, my_turn = False)\n",
    "            if eval == -100:\n",
    "                return (-1,-1), -100\n",
    "            if eval > best_score:\n",
    "                best_score = eval\n",
    "                best_move = move\n",
    "            alpha = max(eval, alpha) \n",
    "            if beta <= alpha:\n",
    "                break\n",
    "        return (best_move, best_score)\n",
    "        \n",
    "    else: \n",
    "        best_score, best_move = float(\"inf\"), None\n",
    "        for move in game.get_active_moves():\n",
    "            _, eval = alphabeta(player, game.forecast_move(move)[0], time_left, depth - 1, alpha, beta, my_turn = True)\n",
    "            if eval < best_score:\n",
    "                best_score = eval\n",
    "                best_move = move\n",
    "            beta = min(eval, beta)\n",
    "            if beta <= alpha:\n",
    "                break\n",
    "        return (best_move, best_score)\n",
    "        \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a58d51",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Iterative Deepening & Player Class\n",
    "This class handles the application of the move finding algorithm as well as the iterative deepening optimization.\n",
    "\n",
    "```python\n",
    "class CustomPlayer:\n",
    "    \"\"\"Player class that chooses a move using the evaluation function\n",
    "    and applied algorithm.\"\"\"\n",
    "\n",
    "    def __init__(self, search_depth=4, eval_fn=OpenMoveEvalFn()):\n",
    "        \n",
    "        self.eval_fn = eval_fn\n",
    "        self.search_depth = search_depth\n",
    "    \n",
    "    def move(self, game, time_left):\n",
    "        \"\"\"Called to determine one move by your agent\n",
    "        Args:\n",
    "            game (Board): The board and game state.\n",
    "            time_left (function): Used to determine time left before timeout\n",
    "\n",
    "        Returns:\n",
    "            tuple: (int,int): Your best move\n",
    "        \"\"\"\n",
    "        \n",
    "        # Iterative deepening step\n",
    "        max_depth = 24\n",
    "        best_moves = []\n",
    "        \n",
    "        for depth in range(1, max_depth + 1):     \n",
    "            best_move, utility = alphabeta(self, game, time_left, depth = self.search_depth - self.search_depth + depth)\n",
    "            best_moves.append(best_move)\n",
    "    \n",
    "            if best_moves[-1] == (-1,-1):\n",
    "                return best_moves[-2]\n",
    "                \n",
    "        return best_move\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9177da",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Challenge the AI agent\n",
    "Ready to take on the battle against the machines? Challenge AI agent in a game of isolation here. Should you defeat level 3, I will share my special evaluation function with you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5b9e52b-6cb6-4012-839c-c223d0226f9a",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78384187cd78461b9b04a428b55b0d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridspecLayout(children=(Button(description=' ', layout=Layout(grid_area='widget001', height='auto', width='au…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ig = InteractiveGame(CustomPlayer(), show_legal_moves=True)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
